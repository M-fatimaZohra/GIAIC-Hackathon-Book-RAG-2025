# Feature Specification: Migration from Cohere to Gemini embeddings for RAG chatbot

**Feature Branch**: `001-cohere-to-gemini-embed`
**Created**: 2025-12-14
**Status**: Draft
**Input**: User description: "Migration from Cohere to Gemini embeddings for RAG chatbot"

## User Scenarios & Testing *(mandatory)*

### User Story 1 - RAG Chatbot Query Processing (Priority: P1)

Users continue to interact with the RAG chatbot for the Physical AI & Humanoid Robotics textbook without noticing any change in functionality. When users submit questions, the system retrieves relevant context from the textbook content and generates responses using the same chat interface.

**Why this priority**: This maintains the core user experience and functionality that users depend on. The migration should be transparent to end users.

**Independent Test**: Can be fully tested by submitting queries to the chatbot and verifying that responses are generated with appropriate context attribution, with no visible difference in user experience.

**Acceptance Scenarios**:

1. **Given** user submits a question to the RAG chatbot, **When** system processes the query, **Then** response is generated with relevant context from the textbook and proper source attribution
2. **Given** user submits multiple queries in succession, **When** system processes each query, **Then** responses maintain quality and relevance comparable to or better than the Cohere-based system

---

### User Story 2 - Content Ingestion Pipeline (Priority: P2)

The system ingests content from the textbook sitemap.xml, processes HTML content into 2000-character chunks, and stores embeddings in the Qdrant vector database using the new Gemini embedding model instead of Cohere.

**Why this priority**: This is the foundational change that enables the migration. Without this, the system cannot function with the new embedding model.

**Independent Test**: Can be tested by running the ingestion pipeline and verifying that documents are properly embedded and stored in Qdrant with 768-dimensional vectors instead of 1024-dimensional vectors.

**Acceptance Scenarios**:

1. **Given** sitemap.xml with textbook content, **When** ingestion pipeline runs with Gemini embeddings, **Then** content is processed and stored in Qdrant with 768-dimensional vectors
2. **Given** existing Qdrant collection with Cohere embeddings, **When** migration process runs, **Then** old collection is replaced with new collection using Gemini embeddings

---

### User Story 3 - System Performance and Rate Limits (Priority: P3)

The system operates with improved rate limits (1500 requests/day vs 1000 requests/month) and reduced API delays (0.5 seconds vs 2 seconds), allowing for better performance and higher throughput.

**Why this priority**: This addresses the primary motivation for the migration - the rate limit and performance issues with Cohere.

**Independent Test**: Can be tested by monitoring API usage patterns and measuring response times during high-traffic scenarios.

**Acceptance Scenarios**:

1. **Given** system processing multiple embedding requests, **When** requests are made within rate limits, **Then** system processes requests with sub-second delays
2. **Given** system at capacity with 1500+ daily requests, **When** additional requests arrive, **Then** appropriate rate limiting responses are returned

---

### Edge Cases

- What happens when the Gemini API is temporarily unavailable during ingestion?
- How does the system handle embedding requests when the Qdrant collection dimensions don't match the expected 768-dimensional vectors?
- What occurs if the ingestion process fails partway through and needs to be restarted?

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: System MUST replace Cohere embed-english-v3.0 API calls with Google's text-embedding-004 API calls
- **FR-002**: System MUST update Qdrant collection to use 768-dimensional vectors instead of 1024-dimensional vectors
- **FR-003**: System MUST re-ingest all textbook content from sitemap.xml using the new embedding model
- **FR-004**: System MUST maintain existing API endpoints and response formats for the chatbot frontend
- **FR-005**: System MUST preserve source URL attribution in chatbot responses
- **FR-006**: System MUST operate with increased rate limits (1500 requests/day vs 1000 requests/month) and reduced API delays (0.5 seconds vs 2 seconds)
- **FR-007**: System MUST support rollback to previous embedding implementation if migration fails
- **FR-008**: System MUST maintain async/await patterns in all embedding operations

### Key Entities

- **Textbook Content**: Represents the Physical AI & Humanoid Robotics textbook content extracted from sitemap.xml, stored as chunks with vector embeddings
- **Vector Embeddings**: 768-dimensional numerical representations of text chunks generated by Gemini text-embedding-004 model
- **Qdrant Collection**: Vector database collection storing embeddings with metadata including source URLs
- **Chat Query**: User input question that gets converted to embedding for similarity search in Qdrant

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Users experience no visible change in chatbot functionality or response quality after migration
- **SC-002**: System supports 1500 embedding requests per day (vs 1000 per month with Cohere) without rate limiting issues
- **SC-003**: Average embedding API response time is under 0.5 seconds (vs 2 seconds with Cohere)
- **SC-004**: Content ingestion pipeline completes successfully with all textbook content embedded using Gemini model
- **SC-005**: Retrieval quality maintains or improves compared to Cohere-based system based on relevance metrics
- **SC-006**: System can be rolled back to Cohere-based implementation within 30 minutes if critical issues arise
